{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935ded18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f864ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/.../hmm_pb1.csv\",sep=',',header=None)\n",
    "data = data-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6afb9d",
   "metadata": {},
   "source": [
    "The dataset __hmm_pb1__ represents a sequence of dice rolls $x$ from the Dishonest casino model. The states of $Y$ are 1=’Fair’ and 2=’Loaded'.\n",
    "\n",
    "Implement the __Viterbi__ algorithm and find the most likely sequence y that generated the observed $x$. Report the obtained sequence $y$ of 1’s and 2’s for verification.\n",
    "\n",
    "Implement the forward and backward algorithms and run them on the observed $x$. You should memorize a common factor $u_{t}$ for the $\\alpha_{t}^{k}$ to avoid floating point\n",
    "underflow, since $\\alpha_{t}^{k}$ quickly becomes very small. The same holds for $\\beta_{t}^{k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdbf6787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "def viterbi(V, a, b, initial_distribution):\n",
    "    T = V.shape[0]\n",
    "    M = a.shape[0]\n",
    " \n",
    "    omega = np.zeros((T, M))\n",
    "    omega[0, :] = np.log(initial_distribution * b[:, V[0]])\n",
    " \n",
    "    prev = np.zeros((T - 1, M))\n",
    " \n",
    "    for t in range(1, T):\n",
    "        for j in range(M):\n",
    "            # Same as Forward Probability\n",
    "            probability = omega[t - 1] + np.log(a[:, j]) + np.log(b[j, V[t]])\n",
    " \n",
    "            # This is our most probable state given previous state at time t (1)\n",
    "            prev[t - 1, j] = np.argmax(probability)\n",
    " \n",
    "            # This is the probability of the most probable state (2)\n",
    "            omega[t, j] = np.max(probability)\n",
    " \n",
    "    # Path Array\n",
    "    S = np.zeros(T)\n",
    " \n",
    "    # Find the most probable last hidden state\n",
    "    last_state = np.argmax(omega[T - 1, :])\n",
    " \n",
    "    S[0] = last_state\n",
    " \n",
    "    backtrack_index = 1\n",
    "    for i in range(T - 2, -1, -1):\n",
    "        S[backtrack_index] = prev[i, int(last_state)]\n",
    "        last_state = prev[i, int(last_state)]\n",
    "        backtrack_index += 1\n",
    " \n",
    "    # Flip the path array since we were backtracking\n",
    "    S = np.flip(S, axis=0)\n",
    " \n",
    "    # Convert numeric values to actual hidden states\n",
    "    result = []\n",
    "    for s in S:\n",
    "        if s == 0:\n",
    "            result.append(\"1\")\n",
    "        else:\n",
    "            result.append(\"2\")\n",
    " \n",
    "    return result\n",
    "  \n",
    "def forward(V, a, b, initial_distribution):\n",
    "    alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    " \n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            # Matrix Computation Steps\n",
    "            #                  ((1x2) . (1x2))      *     (1)\n",
    "            #                        (1)            *     (1)\n",
    "            alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t]]\n",
    " \n",
    "    return alpha\n",
    "\n",
    "def backward(V, a, b):\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    " \n",
    "    # setting beta(T) = 1\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]).dot(a[j, :])\n",
    " \n",
    "    return beta\n",
    "\n",
    "def baum_welch(V, a, b, initial_distribution, n_iter=100):\n",
    "    M = a.shape[0]\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, V[t + 1]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    " \n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    " \n",
    "        K = b.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            b[:, l] = np.sum(gamma[:, V == l], axis=1)\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    " \n",
    "    return {\"a\":a, \"b\":b}\n",
    " \n",
    "data = pd.read_csv(\"C:/Users/.../hmm_pb1.csv\",sep=',',header=None)\n",
    "data = data-1 \n",
    "V = np.squeeze(data.T.values)\n",
    " \n",
    "# Transition Probabilities\n",
    "a = np.array([[0.95,0.05],\n",
    "              [0.05,0.95]])\n",
    "a = a / np.sum(a, axis=1)\n",
    " \n",
    "# Emission Probabilities\n",
    "b = np.array(((1/6,1/6,1/6,1/6,1/6,1/6), (1/10,1/10,1/10,1/10,1/10,1/2)))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    " \n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    " \n",
    " \n",
    "print(viterbi(V, a, b, initial_distribution))\n",
    "alpha = forward(V,a,b,initial_distribution)\n",
    "beta = backward(V,a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a467c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': array([[0.99547791, 0.00452209],\n",
       "        [0.        , 1.        ]]),\n",
       " 'b': array([[0.15827325, 0.18077601, 0.20350386, 0.06783139, 0.12993236,\n",
       "         0.25968314],\n",
       "        [0.        , 0.09326948, 0.0742221 , 0.1113928 , 0.02352628,\n",
       "         0.69758934]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = baum_welch(V,a,b,initial_distribution,n_iter=10000)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c79ba91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2',\n",
       " '2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi(V,a,b,initial_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb395a0a",
   "metadata": {},
   "source": [
    "Report $\\alpha_{123}^{1}/\\alpha_{123}^{2}$ and $\\beta_{123}^{1}/\\beta_{123}^{2}$, where the counting starts from $t =1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94fe2747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1890981879274012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[123,0]/alpha[123,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df802e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.842052019542529"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[123,0]/beta[123,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
